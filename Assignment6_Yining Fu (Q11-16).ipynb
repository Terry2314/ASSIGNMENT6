{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier:\n",
    "\n",
    "Random forests already have built-in feature importance measures derived from the mean decrease in impurity or the mean decrease in accuracy of the tree nodes when a particular feature is used for splitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Feature Selection - Accuracy: 1.0\n",
      "Random Forest with Feature Selection - AUC: 0.3214285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "k = 10\n",
    "top_k_indices = feature_importances.argsort()[-k:][::-1]\n",
    "\n",
    "X_train_selected = X_train.iloc[:, top_k_indices]\n",
    "X_test_selected = X_test.iloc[:, top_k_indices]\n",
    "\n",
    "random_forest_selected = RandomForestClassifier(random_state=1)\n",
    "random_forest_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_selected = random_forest_selected.predict(X_test_selected)\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "auc_selected = roc_auc_score(y_test, random_forest_selected.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "print(\"Random Forest with Feature Selection - Accuracy:\", accuracy_selected)\n",
    "print(\"Random Forest with Feature Selection - AUC:\", auc_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM, we can use techniques like Recursive Feature Elimination (RFE) or SelectKBest to select the most informative features before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Feature Selection - Accuracy: 1.0\n",
      "SVM with Feature Selection - AUC: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "rfe = RFE(estimator=svm_model, n_features_to_select=k, step=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected = X_train.iloc[:, rfe.support_]\n",
    "X_test_selected = X_test.iloc[:, rfe.support_]\n",
    "\n",
    "svm_selected = SVC(kernel='linear', probability=True)\n",
    "svm_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "y_proba_selected = svm_selected.predict_proba(X_test_selected)[:, 1]\n",
    "auc_selected = roc_auc_score(y_test, y_proba_selected)\n",
    "\n",
    "print(\"SVM with Feature Selection - Accuracy:\", accuracy_selected)\n",
    "print(\"SVM with Feature Selection - AUC:\", auc_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Feature Selection - Accuracy: 0.975\n",
      "Random Forest with Feature Selection - AUC: 0.35714285714285715\n",
      "SVM with Feature Selection - Accuracy: 0.9583333333333334\n",
      "SVM with Feature Selection - AUC: 0.026571428571428548\n"
     ]
    }
   ],
   "source": [
    "random_forest_selected = RandomForestClassifier(random_state=1)\n",
    "random_forest_selected.fit(X_train_selected, y_train)\n",
    "y_pred_selected_rf = random_forest_selected.predict(X_test_selected)\n",
    "accuracy_selected_rf = accuracy_score(y_test, y_pred_selected_rf)\n",
    "auc_selected_rf = roc_auc_score(y_test, random_forest_selected.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "svm_selected = SVC(kernel='linear', probability=True)\n",
    "svm_selected.fit(X_train_selected, y_train)\n",
    "y_pred_selected_svm = svm_selected.predict(X_test_selected)\n",
    "accuracy_selected_svm = accuracy_score(y_test, y_pred_selected_svm)\n",
    "auc_selected_svm = roc_auc_score(y_test, svm_selected.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "print(\"Random Forest with Feature Selection - Accuracy:\", accuracy_selected_rf)\n",
    "print(\"Random Forest with Feature Selection - AUC:\", auc_selected_rf)\n",
    "print(\"SVM with Feature Selection - Accuracy:\", accuracy_selected_svm)\n",
    "print(\"SVM with Feature Selection - AUC:\", auc_selected_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both classifiers demonstrated similar accuracy in predicting class labels, with the Random Forest classifier achieving a slightly higher AUC score.\n",
    "\n",
    "- While both classifiers performed well in terms of accuracy, the Random Forest classifier's higher AUC score suggests that it may be more effective in ranking instances by their likelihood of belonging to the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictor Variables and Coefficients:\n",
      "pe: 1.0853612237222734\n",
      "sc: 0.946551056245395\n",
      "al: 0.9013667373936388\n",
      "hemo: -0.5496185568031066\n",
      "htn: 0.5469077051944204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=1000) \n",
    "logistic_regression.fit(X, y)\n",
    "\n",
    "coefficients = logistic_regression.coef_[0]\n",
    "feature_coefficients = dict(zip(X.columns, coefficients))\n",
    "sorted_coefficients = sorted(feature_coefficients.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top Predictor Variables and Coefficients:\")\n",
    "for feature, coefficient in sorted_coefficients[:5]:\n",
    "    print(f\"{feature}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Larger absolute coefficients indicate stronger influence of the corresponding predictor variables on the classification decision.\n",
    "\n",
    "- By examining the top predictor variables with large coefficients, we can identify key clinical indicators that are significantly associated with the presence of chronic kidney disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           2       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n",
      "Cluster: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "Cluster: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "Comparison:\n",
      "12\n",
      "Random Forest with Feature Selection - Accuracy: 0.975\n",
      "Random Forest with Feature Selection - AUC: 0.35714285714285715\n",
      "SVM with Feature Selection - Accuracy: 0.9583333333333334\n",
      "SVM with Feature Selection - AUC: 0.026571428571428548\n",
      "14\n",
      "New Classifier - Accuracy: 0.5166666666666667\n",
      "New Classifier - AUC: 0.5028571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "X_train_clusters = kmeans.fit_predict(X_train)\n",
    "\n",
    "classifiers = {}\n",
    "\n",
    "unique_clusters = set(X_train_clusters)\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    X_train_cluster = X_train[X_train_clusters == cluster]\n",
    "    y_train_cluster = y_train[X_train_clusters == cluster] \n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train_cluster, y_train_cluster)\n",
    "    classifiers[cluster] = classifier\n",
    "\n",
    "X_test_clusters = kmeans.predict(X_test)\n",
    "\n",
    "y_pred_new = []  \n",
    "\n",
    "for cluster, classifier in classifiers.items():\n",
    "    X_test_cluster = X_test[X_test_clusters == cluster]\n",
    "    y_test_cluster = y_test[X_test_clusters == cluster]\n",
    "    y_pred_cluster = classifier.predict(X_test_cluster)\n",
    "    y_pred_new.extend(y_pred_cluster)  \n",
    "\n",
    "    print(f\"Cluster: {cluster}\")\n",
    "    print(classification_report(y_test_cluster, y_pred_cluster))\n",
    "\n",
    "accuracy_new = accuracy_score(y_test, y_pred_new)\n",
    "auc_new = roc_auc_score(y_test, y_pred_new)  \n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(\"12\")\n",
    "print(\"Random Forest with Feature Selection - Accuracy:\", accuracy_selected_rf)\n",
    "print(\"Random Forest with Feature Selection - AUC:\", auc_selected_rf)\n",
    "print(\"SVM with Feature Selection - Accuracy:\", accuracy_selected_svm)\n",
    "print(\"SVM with Feature Selection - AUC:\", auc_selected_svm)\n",
    "print(\"14\")\n",
    "print(\"New Classifier - Accuracy:\", accuracy_new)\n",
    "print(\"New Classifier - AUC:\", auc_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, the accuracy in 14 is lower than that in 12, but the AUC has increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haoyang Huang, 400302198, Question 1-5\n",
    "\n",
    "Xinshan Li, 400248868, Question 6-10, Set up Github\n",
    "\n",
    "Yining Fu, 400300139, Question 11-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Terry2314/ASSIGNMENT6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
